{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from scipy import ndimage\n",
    "import os, sys\n",
    "import math\n",
    "import pickle\n",
    "import model_utils as modutil\n",
    "import data_utils as datutil\n",
    "import uncertainty_calibration as unc_cal\n",
    "import hmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data loader initialization\n",
    "trainloader1 = datutil.generate_dataloaders('CIFAR10_TRAIN', batch_size=50, shuffle=True, num_workers=2)\n",
    "testloader1 = datutil.generate_dataloaders('CIFAR10_TEST', batch_size=10, shuffle=False, num_workers=2)\n",
    "validloader1 = datutil.generate_dataloaders('CIFAR100_TEST', batch_size=10, shuffle=False, num_workers=2)\n",
    "\n",
    "trainloader2 = datutil.generate_dataloaders('ENCODED640_D28_CIFAR10_TRAIN', batch_size=50, shuffle=True, num_workers=2)\n",
    "testloader2 = datutil.generate_dataloaders('ENCODED640_D28_CIFAR10_TEST', batch_size=10, shuffle=False, num_workers=2)\n",
    "validloader2 = datutil.generate_dataloaders('ENCODED640_D28_CIFAR10_VALID', batch_size=10, shuffle=False, num_workers=2)\n",
    "\n",
    "# Cifar-100 interesting classes (used during out-of-class entropy calculation)\n",
    "interesting_labels = [0, 1, 16, 17, 20, 21, 29, 39, 40, 49, 57, 71, 72, 73, 76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model to train/load/analyse\n",
    "# user defined params\n",
    "models = [{'model_type' : \"ModifiedWideResNet+GP\",\n",
    "    'saved_checkpoint_name' : \"ModifiedWideResNet+GP_depth-28_lr-0.1_mom-0.9_wd-0.0005_FC-_acc-91.63-2019-05-23-01.29\",\n",
    "    'fc_setup' : [],\n",
    "    'load_model' : True,\n",
    "    'train_model' : False,\n",
    "    'train_epoch' : 50,\n",
    "    'num_classes' : 10,\n",
    "    'weight_decay' : 3e-4,\n",
    "    'predef_test_acc' : 91,\n",
    "    'depth' : 28,\n",
    "    'grid_size' : 64,\n",
    "    'kernel_net' : 'ModifiedWideResNet',\n",
    "#     'gp_kernel_feature' : 640,\n",
    "    'print_init_model_state' : False},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    \n",
    "    if 'encoded' not in model['model_type']:\n",
    "        trainloader = trainloader1\n",
    "        testloader = testloader1\n",
    "        validloader = validloader1\n",
    "    else:\n",
    "        trainloader = trainloader2\n",
    "        testloader = testloader2\n",
    "        validloader = validloader2\n",
    "        \n",
    "    print('='*20, \"Loading Model\", '='*20,)\n",
    "    modutil.refresh_params()\n",
    "    for propt in model:\n",
    "        if propt in modutil.__dict__:\n",
    "            modutil.__dict__[propt] = model[propt]\n",
    "        else:\n",
    "            print(\"Model property '%s' not found!\"%(propt))\n",
    "    \n",
    "    #load / train the model\n",
    "    modutil.load_train(trainloader, testloader)\n",
    "    if model['train_model']:\n",
    "        print(\"Saving model!\")\n",
    "        modutil.save_model()\n",
    "\n",
    "    # param_list = param_chain if 'mcmc' in model['model_type'] else []\n",
    "    # Perform evaluation on model\n",
    "    #modutil.validate(\"out-of-class\", validloader, interesting_labels=interesting_labels)\n",
    "    print(\"Validation (out of class) data analysis performed\")\n",
    "\n",
    "    #modutil.validate(\"test\", testloader)\n",
    "    print(\"Test data analysis performed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(unc_cal)\n",
    "prob_cutoffs = [(i+1)/30.0 for i in range(30)]\n",
    "unc_cal.calib_reliab_plots(models, prob_cutoffs, ECE_auto_binning=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = modutil.return_model()\n",
    "net.eval()\n",
    "import json\n",
    "data = {'feature': np.array([]), 'label': np.array([])}\n",
    "file_name = \"encoded28x10WideResNet_CIFAR10_640_valid\"\n",
    "device = modutil.device\n",
    "file_count = 0\n",
    "\n",
    "for i, dat in enumerate(validloader1, 0):\n",
    "\n",
    "    inputs, labels = dat\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    output = net.extract_feature(inputs)\n",
    "    if len(data['feature']) > 0:\n",
    "        data['feature'] = np.concatenate((data['feature'], output.detach().cpu().numpy()), axis=0)\n",
    "        data['label'] = np.concatenate((data['label'], labels.detach().cpu().numpy()), axis=0)\n",
    "    else:\n",
    "        data['feature'] = output.detach().cpu().numpy()\n",
    "        data['label'] = labels.detach().cpu().numpy()\n",
    "        \n",
    "    if len(data['feature'])//10000 > 0:\n",
    "        \n",
    "        data['feature'] = data['feature'].tolist()\n",
    "        data['label'] = data['label'].tolist()\n",
    "        \n",
    "        file_count += 1\n",
    "        file_n = file_name + str(file_count)\n",
    "        print(\"dumping\", len(data['label']), \"size data at\", file_n)\n",
    "        with open(file_n, 'wb') as part_pickle:\n",
    "            pickle.dump(data, part_pickle)\n",
    "        data = {'feature': np.array([]), 'label': np.array([])}\n",
    "\n",
    "if len(data['feature']) > 0:\n",
    "    \n",
    "    data['feature'] = data['feature'].tolist()\n",
    "    data['label'] = data['label'].tolist()\n",
    "        \n",
    "    file_count += 1\n",
    "    file_n = file_name + str(file_count)\n",
    "    print(\"dumping\", len(data['label']), \"size data at\", file_n)\n",
    "    with open(file_n, 'wb') as part_pickle:\n",
    "        pickle.dump(data, part_pickle)\n",
    "    data = {'feature': np.array([]), 'label': np.array([])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net.extract_feature(inputs)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load / train the model\n",
    "net = modutil.return_model()\n",
    "\n",
    "rng = np.random.RandomState(seed=1234)\n",
    "system = hmc.systems.EuclideanMetricSystem(net.pot_energy_FC, grad_pot_energy=net.grad_pot_energy_FC)\n",
    "integrator = hmc.integrators.LeapfrogIntegrator(system, step_size=0.001)\n",
    "sampler = hmc.samplers.StaticMetropolisHMC(system, integrator, rng, n_step=1)\n",
    "chains, chain_stats = sampler.sample_chain(\n",
    "    n_sample=5, init_state=net.return_init_MCMC_state(),\n",
    "    chain_var_funcs={'pos': lambda state: state.pos,\n",
    "                     'pot_energy': lambda state: system.pot_energy(state),\n",
    "                     'kin_energy': lambda state: system.kin_energy(state)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = hmc.states.HamiltonianState(net.return_init_MCMC_state().copy())\n",
    "state.mom = system.sample_momentum(state, rng)\n",
    "n_step = 100\n",
    "hs = np.empty(n_step)\n",
    "hs[0] = system.h(state)\n",
    "for s in range(1, n_step):\n",
    "    state = integrator.step(state)\n",
    "    hs[s] = system.h(state)\n",
    "    if s % 10 == 0:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.plot(hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.zeros(2570) #rng.normal(size=state.pos.shape)\n",
    "v[0] = 1.\n",
    "epsilon = 1e-6\n",
    "grad_fd = (\n",
    "    net.pot_energy_FC(state.pos + epsilon * v) -\n",
    "    net.pot_energy_FC(state.pos - epsilon * v)) / (2 * epsilon)\n",
    "grad_net = v @ net.grad_pot_energy_FC(state.pos)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.grad_pot_energy_FC(state.pos)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_stats['accept_prob'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_stats['accept_prob'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains['pot_energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(chains['kin_energy'])\n",
    "chains['pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modutil.prob_cutoffs=[(i+1)/30.0 for i in range(30)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
