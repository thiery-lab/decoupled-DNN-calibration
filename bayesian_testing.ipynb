{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from scipy import ndimage\n",
    "import os, sys\n",
    "import math\n",
    "import pickle\n",
    "import model_utils as modutil\n",
    "import data_utils as datutil\n",
    "import hmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data loader initialization\n",
    "trainloader1 = datutil.generate_dataloaders('CIFAR10_TRAIN', batch_size=50, shuffle=True, num_workers=2)\n",
    "testloader1 = datutil.generate_dataloaders('CIFAR10_TEST', batch_size=10, shuffle=False, num_workers=2)\n",
    "validloader1 = datutil.generate_dataloaders('CIFAR100_TEST', batch_size=10, shuffle=False, num_workers=2)\n",
    "\n",
    "trainloader2 = datutil.generate_dataloaders('ENCODED256_D110_CIFAR10_TRAIN', batch_size=50, shuffle=True, num_workers=2)\n",
    "testloader2 = datutil.generate_dataloaders('ENCODED256_D110_CIFAR10_TEST', batch_size=10, shuffle=False, num_workers=2)\n",
    "validloader2 = datutil.generate_dataloaders('ENCODED256_D110_CIFAR10_VALID', batch_size=10, shuffle=False, num_workers=2)\n",
    "\n",
    "# Cifar-100 interesting classes (used during out-of-class entropy calculation)\n",
    "interesting_labels = [0, 1, 16, 17, 20, 21, 29, 39, 40, 49, 57, 71, 72, 73, 76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model to train/load/analyse\n",
    "# user defined params\n",
    "models = [{'model_type' : \"PreResNet110\",     # <Kernel_name> + <GP>\n",
    "    'saved_checkpoint_name' : \"PreResNet110_depth-110_lr-0.1_mom-0.9_wd-0.0001_FC-10_acc-91.07-2019-06-18-19.52\",\n",
    "    'fc_setup' : [],\n",
    "    'load_model' : True,\n",
    "    'train_model' : False,\n",
    "    'train_epoch' : 20,\n",
    "    'num_classes' : 10,\n",
    "    'weight_decay' : 3e-4,\n",
    "    'predef_test_acc' : 90,\n",
    "    'depth' : 110,\n",
    "    'grid_size' : 64,\n",
    "    'gp_kernel_feature' : 256, # 256, 640\n",
    "    'print_init_model_state' : False},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    \n",
    "    if 'encoded' not in model['model_type']:\n",
    "        trainloader = trainloader1\n",
    "        testloader = testloader1\n",
    "        validloader = validloader1\n",
    "    else:\n",
    "        trainloader = trainloader2\n",
    "        testloader = testloader2\n",
    "        validloader = validloader2\n",
    "        \n",
    "    print('='*20, \"Loading Model\", '='*20,)\n",
    "    modutil.refresh_params()\n",
    "    for propt in model:\n",
    "        if propt in modutil.__dict__:\n",
    "            modutil.__dict__[propt] = model[propt]\n",
    "        else:\n",
    "            print(\"Model property '%s' not found!\"%(propt))\n",
    "    \n",
    "    #load / train the model\n",
    "    modutil.load_train(trainloader, testloader)\n",
    "    if model['train_model']:\n",
    "        print(\"Saving model!\")\n",
    "        modutil.save_model()\n",
    "\n",
    "    # param_list = param_chain if 'mcmc' in model['model_type'] else []\n",
    "    # Perform evaluation on model\n",
    "    # modutil.validate(\"out-of-class\", validloader, interesting_labels=interesting_labels)\n",
    "    print(\"Validation (out of class) data analysis performed\")\n",
    "\n",
    "    # modutil.validate(\"test\", testloader)\n",
    "    print(\"Test data analysis performed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = 'saved_predictions/' + models[0]['saved_checkpoint_name'] + '.testpred'\n",
    "prob_cutoffs = [(i+1)/30.0 for i in range(30)]\n",
    "\n",
    "with open(test_file, 'rb') as test_file:\n",
    "    stats = pickle.load(test_file)\n",
    "    targets = stats['targets']\n",
    "    preds = stats['predictions']\n",
    "    probs = stats['probs']\n",
    "    ece, ece_avg = modutil.calculate_ECE(probs, preds, targets, ECE_bin=prob_cutoffs)\n",
    "\n",
    "print(ece, ece_avg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
