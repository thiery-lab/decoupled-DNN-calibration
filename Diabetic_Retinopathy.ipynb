{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage\n",
    "import os, sys\n",
    "import math\n",
    "import pickle\n",
    "import data_utils as datutil\n",
    "import datetime as dt\n",
    "import hmc\n",
    "import torch.utils.data as Data\n",
    "from models import *\n",
    "import gpytorch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retinopathy dataset definition: removes bad images that cant be read, includes first 30000 images from test set into training set so that the train:test split is roughly 75:25\n",
    "\n",
    "Also there is a weights attribute that has class weights as their respective frequency inversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class retinopathy_dataset(Data.Dataset):\n",
    "    '''DIABETIC RETINOPATHY dataset downloaded from\n",
    "    kaggle link : https://www.kaggle.com/c/diabetic-retinopathy-detection/data\n",
    "    root : location of data files\n",
    "    train : whether training dataset (True) or test (False)\n",
    "    transform : torch image transformations\n",
    "    binary : whether healthy '0' vs damaged '1,2,3,4' binary detection (True) \n",
    "            or multiclass (False)\n",
    "    balance: whether to balance the classes, if yes then attribute weights and\n",
    "            sample weights will be calculated\n",
    "    '''\n",
    "\n",
    "    def __init__(self, root, train, transform, binary=True, balance=True):\n",
    "        root += 'DIABETIC_RETINOPATHY_CRPD/'\n",
    "        if train:\n",
    "            self.img_dir = root + 'train/'\n",
    "            label_csv = root + 'trainLabels.csv'\n",
    "            with open(label_csv, 'r') as label_file:\n",
    "                label_tuple = [line.strip().split(',')[:2] for line in label_file.readlines()[1:]]\n",
    "            self.imgs = [item[0] for item in label_tuple]\n",
    "            self.labels = [int(item[1]) for item in label_tuple]\n",
    "\n",
    "            with open(label_csv.replace('train', 'test'), 'r') as label_file:\n",
    "                label_tuple = [line.strip().split(',')[:2] for line in label_file.readlines()[1:]]\n",
    "            self.imgs += [item[0] for item in label_tuple[:30000]]\n",
    "            self.labels += [int(item[1]) for item in label_tuple[:30000]]\n",
    "\n",
    "        else:\n",
    "            self.img_dir = root + 'test/'\n",
    "            label_csv = root + 'testLabels.csv'\n",
    "            with open(label_csv, 'r') as label_file:\n",
    "                label_tuple = [line.strip().split(',')[:2] for line in label_file.readlines()[1:]]\n",
    "            self.imgs = [item[0] for item in label_tuple[30000:]]\n",
    "            self.labels = [int(item[1]) for item in label_tuple[30000:]]\n",
    "\n",
    "        self.transform = transform\n",
    "        self.binary = binary\n",
    "        if self.binary:\n",
    "            self.labels = [min(label, 1) for label in self.labels]\n",
    "\n",
    "        # Discard bad images\n",
    "        bad_images = ['10_left']\n",
    "        for img in bad_images:\n",
    "            if img in self.imgs:\n",
    "                index = self.imgs.index(img)\n",
    "                self.imgs = self.imgs[:index] + self.imgs[index+1:]\n",
    "                self.labels = self.labels[:index] + self.labels[index+1:]\n",
    "\n",
    "        # Make all these better\n",
    "        classes, counts = np.unique(np.array(self.labels), return_counts=True)\n",
    "        deviation = np.std(counts) / np.mean(counts)\n",
    "        if deviation > 0.05 and train:\n",
    "            weights = 1./torch.tensor(counts, dtype=torch.float)\n",
    "            weights = weights / weights.sum()\n",
    "            self.weights = weights.numpy().tolist()\n",
    "#             self.sample_weights = weights[self.labels]\n",
    "            print('Class weights calculated as ', dict(zip(classes, weights.numpy())))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.imgs[idx]\n",
    "        try:\n",
    "            image = Image.open(self.img_dir + img_name + '.jpeg')\n",
    "        except:\n",
    "            image = Image.open(self.img_dir.replace('train', 'test') + img_name + '.jpeg')\n",
    "        image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/data02/'\n",
    "transform = transforms.Compose([transforms.Resize((512, 512)),\n",
    "                                transforms.ColorJitter(brightness=(0.7, 1.3), contrast=(0.7, 1.3)),\n",
    "                                transforms.ToTensor()])\n",
    "trainData = retinopathy_dataset(root=directory, train=True, transform=transform, binary=True, balance=True)\n",
    "trainloader = Data.DataLoader(trainData, batch_size=200, shuffle=True, num_workers=10)\n",
    "print(\"Training dataset length:\", len(trainloader.dataset))\n",
    "testData = retinopathy_dataset(root=directory, train=False, transform=transform, binary=True, balance=True)\n",
    "testloader = Data.DataLoader(testData, batch_size=50, shuffle=True, num_workers=10)\n",
    "print(\"Test dataset length:\", len(testloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_mod_factor(epoch, lr_init, lr_end, end_epoch):\n",
    "    lr_ratio = lr_end / lr_init\n",
    "    t = (epoch) / (end_epoch*1.0)\n",
    "    if t < 0.4:\n",
    "        factor = 1.0\n",
    "    elif t <= 0.9:\n",
    "        factor = 1.0 - (1.0 - lr_ratio) * (t - 0.4) / 0.5\n",
    "    else:\n",
    "        factor = lr_ratio\n",
    "    return factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is taken from 'models/diab_retin_kaggle.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1'\n",
    "num_classes = 2\n",
    "weight_decay = 0.0003\n",
    "\n",
    "final_model = DiabRetinModelSimpleR256()\n",
    "final_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize images generated after transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_iterator = iter(trainloader)\n",
    "inputs, labels = image_iterator.__next__()\n",
    "img_np = inputs.cpu().numpy()\n",
    "plt.imshow(img_np[0].transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR Finder cell, can switch to Adam if needed, but the loss jumps to 1e17 if Adam is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(final_model.parameters(), weight_decay=weight_decay, lr=1e-5, momentum=0.6)\n",
    "class_weights = torch.tensor(trainData.weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "lr_finder = LRFinder(model=final_model, optimizer=optimizer, criterion=criterion, device=device)\n",
    "lr_finder.range_test(trainloader, end_lr=10, num_iter=200, step_mode=\"exp\")\n",
    "lr_finder.plot(fname='lr_probing.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss = 0\n",
    "epoch_count = 20\n",
    "lr = 0.01\n",
    "end_lr = 0.0001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(final_model.parameters(), weight_decay=weight_decay, lr=lr, momentum=0.6)\n",
    "criterion.to(device)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.001, max_lr=0.08, step_size_up=5, step_size_down=10)\n",
    "\n",
    "for epoch in range(0, epoch_count):  # loop over the dataset multiple times\n",
    "\n",
    "    factor = learning_rate_mod_factor(epoch, lr, end_lr, epoch_count)\n",
    "    for i, g in enumerate(optimizer.param_groups):\n",
    "        print(\"Learning rate for param %d is currently %.4f\" %(i, g['lr']))\n",
    "        g['lr'] = lr * factor\n",
    "\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.sum().backward()\n",
    "        optimizer.step()\n",
    "        running_loss = 0.9*running_loss + 0.1*loss.item() if running_loss != 0 else loss.item()\n",
    "\n",
    "    if i% (len(trainloader) // 10) == 0:\n",
    "        print('[%d, %5d] loss: %.4f' %(epoch + 1, i, running_loss))\n",
    "    \n",
    "    print(\"=== Accuracy using SGD params ===\")\n",
    "    accuracy, ece, sce = nbutils.validate(model=final_model, dataloader=testloader, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
